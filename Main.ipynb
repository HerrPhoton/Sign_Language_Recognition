{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from tqdm import tqdm; tqdm.pandas();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Устройство для обучения\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Директории с файлами\n",
    "DATASET_DIR = './train_landmark_files'\n",
    "CLASSES_DIR = './Dataset'\n",
    "\n",
    "# Параметры загрузчиков\n",
    "BACTH_SIZE  = 1\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY  = True\n",
    "\n",
    "# Параметры оптимизатора\n",
    "WEIGHT_DECAY  = 5e-5\n",
    "LEARNING_RATE = 5e-3\n",
    "\n",
    "MEAN = [0.3395, 0.3431, 0.3020]\n",
    "STD  = [0.3908, 0.3897, 0.3542]\n",
    "\n",
    "# Параметры планировщика\n",
    "FACTOR    = 0.1\n",
    "PATIENCE  = 10\n",
    "THRESHOLD = 1e-4\n",
    "\n",
    "# Параметры модели\n",
    "ENCODER         = 'resnet50'\n",
    "ENCODER_WEIGHTS = None\n",
    "\n",
    "# Параметры обучения\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "# Параметры датасета\n",
    "ORIGINAL_SIZE = 1500\n",
    "PADED_SIZE    = 1536\n",
    "PATCH_SIZE    = 256 \n",
    "VALID_PART = 0.1\n",
    "TEST_PART  = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка аугментаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit = 0.1, contrast_limit = 0.1, p = 0.5),\n",
    "        A.PadIfNeeded(PADED_SIZE, PADED_SIZE, border_mode = 0),\n",
    "        A.Normalize(mean = MEAN, std = STD),        \n",
    "        ToTensorV2()])\n",
    "\n",
    "val_test_transform = A.Compose([\n",
    "    A.PadIfNeeded(PADED_SIZE, PADED_SIZE, border_mode = 0),\n",
    "    A.Normalize(mean = MEAN, std = STD),\n",
    "    ToTensorV2()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распределение файлов по классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  \n",
       "0   blow  \n",
       "1   wait  \n",
       "2  cloud  \n",
       "3   bird  \n",
       "4   owie  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_handle(path, sign):\n",
    "\n",
    "    if not os.path.exists(os.path.join(CLASSES_DIR, sign)):        \n",
    "        os.mkdir(os.path.join(CLASSES_DIR, sign))\n",
    "\n",
    "    shutil.move(path, os.path.join(CLASSES_DIR, sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CLASSES_DIR):\n",
    "    os.mkdir(CLASSES_DIR)\n",
    "\n",
    "    [path_handle(path, sign) for path, _, _, sign in zip(df['path'], df['participant_id'], df['sequence_id'], df['sign'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разделение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DatasetFolder.__init__() missing 1 required positional argument: 'loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m DatasetFolder(CLASSES_DIR)\n\u001b[0;32m      3\u001b[0m \u001b[39m# n_val   = len(dataset) * VALID_PART\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# n_test  = len(dataset) * TEST_PART\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# n_train = len(dataset) - n_val - n_test\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[39m# train_dataset, val_dataset, test_dataset = random_split(dataset, [n_train, n_val, n_test])\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mlen\u001b[39m(dataset)\n",
      "\u001b[1;31mTypeError\u001b[0m: DatasetFolder.__init__() missing 1 required positional argument: 'loader'"
     ]
    }
   ],
   "source": [
    "dataset = DatasetFolder(CLASSES_DIR)\n",
    "\n",
    "# n_val   = len(dataset) * VALID_PART\n",
    "# n_test  = len(dataset) * TEST_PART\n",
    "# n_train = len(dataset) - n_val - n_test\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "len(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
