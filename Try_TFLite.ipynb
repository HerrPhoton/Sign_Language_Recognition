{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С учетом того, что наши лучшие веса сохранены в формате pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "MAX_ROWS = 100\n",
    "MAX_COL = 9\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "summary(model=model, input_size =(BATCH_SIZE, MAX_ROWS, MAX_COL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_infe(Net):#наследуемся от предыдущей модели\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        x = torch.where(torch.isnan(x), torch.tensor(0.0,dtype=torch.float32).to(DEVICE),x)\n",
    "        x = torch.mean(x, dim = 0, keepdim = False)\n",
    "        x = self.flatten(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        x = self.l5(x)\n",
    "        return self.softmax(x)\n",
    "model_infe = Net_infe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_infe.load_state_dict(torch.load('/kaggle/working/model.pth'), strict=False)\n",
    "# Аккуратно!!!! Тут путь не тот - у нас в другом файле веса!!!\n",
    "model_infe = model_infe.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (BATCH_SIZE,MAX_ROWS,MAX_COL)\n",
    "saved_onnx = 'model.onnx'\n",
    "sample_input = torch.rand(input_size).to(DEVICE)\n",
    "model_infe.eval()\n",
    "preds = model_infe(sample_input)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model_infe,\n",
    "    sample_input,\n",
    "    saved_onnx,\n",
    "    verbose=False,\n",
    "    input_names=['inputs'],\n",
    "    output_names=['outputs'],\n",
    "    opset_version=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "model_onnx = onnx.load(saved_onnx)\n",
    "onnx.checker.check_model(model_onnx)\n",
    "print(onnx.helper.printable_graph(model_onnx.graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "\n",
    "tf_rep = prepare(model_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_path = \"model.pb\"\n",
    "tf_rep.export_graph(pb_path)\n",
    "\n",
    "assert os.path.exists(pb_path)\n",
    "print(\".pb model converted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = tf_rep.inputs\n",
    "output_nodes = tf_rep.outputs\n",
    "print(\"The names of the input nodes are: {}\".format(input_nodes))\n",
    "print(\"The names of the output nodes are: {}\".format(output_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(pb_path)\n",
    "tflite_rep = converter.convert()\n",
    "\n",
    "tflite_model_path = 'model.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip submission.zip $tflite_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(tflite_model_path)\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "list_label = train_df['sign'].unique()#У нас словарь с ключами  по-другому называется\n",
    "\n",
    "for i in range(100):\n",
    "    frames = load_relevant_data_subset(f'{train_df.iloc[i].path}')\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "    print(f\"Predicted label: {p2s_map[sign]}, Actual Label: {train_df.iloc[i].sign}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
